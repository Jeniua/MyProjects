import pandas as pd
import numpy as np
import warnings
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.model_selection import GridSearchCV
from sklearn.linear_model import LinearRegression
from sklearn.model_selection import cross_val_score
from xgboost import XGBRegressor
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_absolute_error


warnings.filterwarnings('ignore')


data_arc = pd.read_csv('/datasets/final_steel/data_arc.csv')
data_bulk = pd.read_csv('/datasets/final_steel/data_bulk.csv')
data_bulk_time = pd.read_csv('/datasets/final_steel/data_bulk_time.csv')
data_gas = pd.read_csv('/datasets/final_steel/data_gas.csv')
data_temp = pd.read_csv('/datasets/final_steel/data_temp.csv')
data_wire = pd.read_csv('/datasets/final_steel/data_wire.csv')
data_wire_time = pd.read_csv('/datasets/final_steel/data_wire_time.csv')



display(data_arc.head(10), data_arc.info())


print(data_arc['Активная мощность'].describe())
data_arc['Активная мощность'].hist(bins = 130, figsize=(12,10))


print(len(data_arc[data_arc['Активная мощность'] >= 2.5])/len(data_arc))



display(data_arc['Реактивная мощность'].describe())
data_arc = data_arc[data_arc['Реактивная мощность'] > 0]
display(data_arc['Реактивная мощность'].describe())
data_arc['Реактивная мощность'].hist(bins = 100, figsize = (12,10))



print(len(data_arc[data_arc['Реактивная мощность'] >= 2])/len(data_arc))


display(data_bulk.head(100), data_bulk.info())


for column in data_bulk.columns:
    if column[0] == 'B':
        print(column)
        display(data_bulk[column].describe())


display(data_bulk_time.head(10), data_bulk_time.info())


display(data_gas.head(10), data_gas.info())

print(data_gas['Газ 1'].describe())
data_gas['Газ 1'].hist(bins = 130,figsize = (12,10))


print(len(data_gas[data_gas['Газ 1'] >= 35])/len(data_gas))


display(data_temp.head(10), data_temp.info())

print(data_temp['Температура'].describe())
data_temp['Температура'].hist(bins = 130, figsize = (12,10))

print(len(data_temp[data_temp['Температура'] >= 1660])/len(data_temp))

display(data_wire.head(10), data_wire.info())

for column in data_wire.columns:
    if column[0] == 'W':
        print(column)
        display(data_wire[column].describe())

display(data_wire_time.head(10),data_wire_time.info())


# ## План работы
# 1) Проведем предобработку данных. Удалим аномалии, заменим пропуски, приведем некоторые значения к нужным типам данных.  
# 2) Отберем целевой признак( конечную температуру из данных по температуре для одной партии)
# 3) Для обучения модели не будем использовать все предоставленные столбцы, с помощью матрицы корреляций найдем те, которые оказывают наибольшее влияние на целевой признак.  
# 5) Проверим на мультиколлинеарность  
# 4) Обучим несколько моделей ( линейная регрессия, XGBRegressor,RandomForestRegressor)  
# 5) Протестируем их и выберем лучшую. 




data_temp = data_temp.rename(columns = {'Температура':'temp', 'Время замера':'measure_time'})
data_arc.columns = ['key', 'start_time','end_time', 'active_power', 'reactive_power']
data_arc['start_time'] = pd.to_datetime(data_arc['start_time'], format='%Y%m%d %H:%M:%S')
data_arc['end_time'] = pd.to_datetime(data_arc['end_time'], format='%Y%m%d %H:%M:%S')
data_temp['measure_time'] = pd.to_datetime(data_temp['measure_time'], format='%Y%m%d %H:%M:%S')



#print(len(data_temp[data_temp['Температура'] >= 1660])/len(data_temp))
#data_temp = data_temp.query('temp >= 1400')
#data_temp['temp'].hist(bins = 100)


# Температура плавления стали 1450-1520 C°, значения ниже 1400 удалим.

# Просуммируем активную и реактивную мощности по номеру партии.

sum_data_arc = data_arc.pivot_table(index = 'key', values = ['active_power', 'reactive_power'], aggfunc = np.sum)
print(sum_data_arc.head())

#print(data_temp.info())
#print(data_temp.head())
#print(data_arc.head())


# Выделим те партии, в которых последний замер температуры был до финального нагрева дугой.

conditions = []
for key in list(data_temp['key'].unique()):
    if ((data_temp[data_temp['key'] == key]['measure_time'].max() < 
        data_arc[data_arc['key'] == key]['end_time'].max())):
            conditions.append(key)

            
#print(bad_keys, len(bad_keys))

print(data_temp.info())

data_temp = data_temp.query('key not in @conditions')


print(data_temp.info())


data_temp = data_temp.dropna()

print(data_temp.info())


# Так же удалим строки, где было сделано только одно измерение температуры.

once_measure_count = (data_temp['key'].value_counts() < 2).sum() 
good_keys = list(data_temp['key'].value_counts().index[:-once_measure_count])
data_temp = data_temp.query('key in @good_keys')


#print(data_temp.info())



pivot_data_temp = data_temp.pivot_table(index= 'key', values = 'measure_time', aggfunc = {'measure_time' :[np.min, np.max]})

pivot_data_temp = pivot_data_temp[['amin', 'amax']]
pivot_data_temp.head()


data_temp_asc = data_temp.sort_values(by = ['measure_time'], ascending = True)
data_temp_asc = data_temp_asc.drop_duplicates(subset=['key'])
del data_temp_asc['measure_time']
data_temp_asc

data_temp_desc = data_temp.sort_values(by = ['measure_time'], ascending = False)
data_temp_desc = data_temp_desc.drop_duplicates(subset=['key'])
del data_temp_desc['measure_time']
data_temp_desc

# Создадим единую таблицу с необходимыми данными.

pivot_data_temp = pivot_data_temp.merge(data_temp_asc,on = 'key')
pivot_data_temp = pivot_data_temp.merge(data_temp_desc,on = 'key')
pivot_data_temp = pivot_data_temp.merge(sum_data_arc,on = 'key')
pivot_data_temp = pivot_data_temp.merge(data_bulk,on = 'key')
pivot_data_temp = pivot_data_temp.merge(data_gas ,on = 'key')
pivot_data_temp = pivot_data_temp.merge(data_wire ,on = 'key')
#pivot_data_temp = pivot_data_temp[['key', 'amin', 'amax','temp_x','temp_y']]
#data_temp = data_temp.rename(columns = {'Температура':'temp', 'Время замера':'measure_time'})\
pivot_data_temp = pivot_data_temp.rename(columns = {'amin':'start_time', 'amax':'end_time','temp_x':'start_temp',
                                                    'temp_y':'end_temp'})


#pivot_data_temp


# Еще при знакомстве с данными можно было заметить, что слобец wire 5 имеет только одно ненулевое значение,поэтому этот столбец просто удалим. Номер партии удалим, так как он никак не влияет на ход процесса и конечную температуру. Так же удалим строки, где пропущено значение конечной температуры.


pivot_data_temp = pivot_data_temp.dropna(subset=['end_temp'])
pivot_data_temp.info()
pivot_data_temp = pivot_data_temp.drop(['Wire 5','key'],axis=1)


# Приведем температуру к целочисленному типу.

pivot_data_temp = pivot_data_temp.fillna(0)
pivot_data_temp['start_temp'] = pd.to_numeric(pivot_data_temp['start_temp'], downcast='integer')
pivot_data_temp['end_temp'] = pd.to_numeric(pivot_data_temp['end_temp'], downcast='integer')


for column in pivot_data_temp.columns:
    if column[0] == 'B':
        pivot_data_temp[f'{column}'] = pd.to_numeric(pivot_data_temp[f'{column}'], downcast='integer')
pivot_data_temp = pivot_data_temp.drop(['start_time', 'end_time'], axis=1)


#pivot_data_temp.info()

data_corr= pivot_data_temp.copy()
corr_heatmap_data = pivot_data_temp.corr()

fig, ax = plt.subplots(figsize=(20,20))
ax.set_xticks(np.arange(len(corr_heatmap_data.index)))
ax.set_yticks(np.arange(len(corr_heatmap_data.index)))

ax.set_xticklabels(corr_heatmap_data.index)
ax.set_yticklabels(corr_heatmap_data.index)

plt.setp(ax.get_xticklabels(), rotation=45, ha="right")

data = corr_heatmap_data.values

for i in range(len(corr_heatmap_data.index)):
    for j in range(len(corr_heatmap_data.index)):
        text = ax.text(j, i, '{:.2}'.format(data[i, j]),
                       ha="center", va="center", color="w")
        
im = ax.imshow(corr_heatmap_data.corr(), cmap='Oranges')


data_corr = data_corr.drop(['reactive_power', 'Wire 8'], axis=1)


data_corr.corr()['end_temp']


# выделим те столбцы, которые больше всего влияют на конечную температуру.


imp_features = []
list_corr = dict(data_corr.corr()['end_temp'])
#print(list_corr)
for i in list_corr:
    if list_corr[f'{i}'] >= 0.1:
        imp_features.append(i)
print(imp_features)


#print(len(pivot_data_temp))


random_state = 12345

features = pivot_data_temp.drop('end_temp', axis=1)
target = pivot_data_temp['end_temp']

features_train, features_test, target_train, target_test = train_test_split(
                                                            features, 
                                                            target, 
                                                            test_size=0.25, 
                                                            random_state=random_state)
cv_counts = 5


# ### Линейная регрессия

regressor = LinearRegression()
cv_MAE_LR = (cross_val_score(regressor, 
                             features_train, 
                             target_train, 
                             cv=cv_counts, 
                             scoring='neg_mean_absolute_error').mean() * -1)
print('Средний MAE ', cv_MAE_LR)


# ### XGBRegressor

regressor = XGBRegressor() 
hyperparams = [{'learning_rate':[x/100 for x in range(1, 51)],
                'random_state':[random_state],
               'silent':[True]}]

clf = GridSearchCV(regressor, hyperparams, scoring='neg_mean_absolute_error', cv=cv_counts)
clf.fit(features_train, target_train)
print("Наиболее подходящие параметры:")
best_params_XGBR = clf.best_params_
print(clf.best_params_)


# ### RandomForestRegressor

regressor = RandomForestRegressor() 
hyperparams = [{'criterion':['mse'],
                'n_estimators':[x for x in range(100, 1001, 50)], 
                'random_state':[random_state]}]

clf = GridSearchCV(regressor, hyperparams, scoring='neg_mean_absolute_error', cv=cv_counts)
clf.fit(features_train, target_train)
print("Наиболее подходящие параметры:")
best_params_RFR = clf.best_params_
print(clf.best_params_)


# ### Проверка моделей

import seaborn as sns
def chart_feature_imp(model):
    feature_imp = pd.Series(model.feature_importances_, index=features_test.columns).sort_values(ascending=False)

    ax = sns.barplot(x=feature_imp, y=feature_imp.index)
    label = ax.set(xlabel='Оценка важности признаков', ylabel='Признаки')
    title = ax.set_title('Визуализация важности признаков')


LR = LinearRegression()
LR.fit(features_train, target_train)
target_predict = LR.predict(features_test)
test_MAE_LR = mean_absolute_error(target_predict, target_test)
print('MAE on test for LinearRegression =', test_MAE_LR)
feature_imprtnr = pd.Series(LR.coef_, index=features_test.columns).sort_values(ascending=False)
ax_lr = sns.barplot(x=feature_imprtnr, y=feature_imprtnr.index)
label_lr = ax.set(xlabel='Оценка важности признаков', ylabel='Признаки')
title_lr = ax.set_title('Визуализация важности признаков')


gxbregressor = XGBRegressor()
gxbregressor.set_params(**best_params_XGBR)
gxbregressor.fit(features_train, target_train)
target_predict = gxbregressor.predict(features_test)
test_MAE_XGBR = mean_absolute_error(target_predict, target_test)
print('Средний MAE ', test_MAE_XGBR)
chart_feature_imp(gxbregressor)
get_ipython().system('[image.png](attachment:image.png)')



random_forest = RandomForestRegressor()
random_forest.set_params(**best_params_RFR)
random_forest.fit(features_train, target_train)
target_predict = random_forest.predict(features_test)
test_MAE_RFR = mean_absolute_error(target_predict, target_test)
print('MAE on test of RandomForestRegressor =', test_MAE_RFR)
chart_feature_imp(random_forest)
get_ipython().system('[image.png](attachment:image.png)')







