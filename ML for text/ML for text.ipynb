{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Подготовка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import nltk\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import SnowballStemmer\n",
    "nltk.download('punkt')\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import re\n",
    "import numpy as np\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, precision_recall_curve\n",
    "import sklearn.metrics\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>52665</td>\n",
       "      <td>Daily Scripture \\n\\n2Th 1:6 1:6 {3} Seeing it ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29740</td>\n",
       "      <td>Welcome!\\n\\nHello , and welcome to Wikipedia! ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14703</td>\n",
       "      <td>\"\\n\\nI left this message\\n\\n\"\"Before anyone ba...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39248</td>\n",
       "      <td>No problem from me regarding adding the portal...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23048</td>\n",
       "      <td>what to do with elitist assholes who do not al...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>101690</td>\n",
       "      <td>Well, if this is indeed original research (and...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30825</td>\n",
       "      <td>Here i found something just for you, you many ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13379</td>\n",
       "      <td>\"::I wouldn't.  Drop it.  It's done. It's WP:O...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46881</td>\n",
       "      <td>Clearly, you both need to lose the mop in orde...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80445</td>\n",
       "      <td>\"\\n\\nTo all Wikipedia Editors of the Jehovah's...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text  toxic\n",
       "52665   Daily Scripture \\n\\n2Th 1:6 1:6 {3} Seeing it ...      0\n",
       "29740   Welcome!\\n\\nHello , and welcome to Wikipedia! ...      0\n",
       "14703   \"\\n\\nI left this message\\n\\n\"\"Before anyone ba...      0\n",
       "39248   No problem from me regarding adding the portal...      0\n",
       "23048   what to do with elitist assholes who do not al...      1\n",
       "101690  Well, if this is indeed original research (and...      0\n",
       "30825   Here i found something just for you, you many ...      0\n",
       "13379   \"::I wouldn't.  Drop it.  It's done. It's WP:O...      0\n",
       "46881   Clearly, you both need to lose the mop in orde...      0\n",
       "80445   \"\\n\\nTo all Wikipedia Editors of the Jehovah's...      0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    143346\n",
      "1     16225\n",
      "Name: toxic, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('/datasets/toxic_comments.csv')\n",
    "display(df.sample(n = 10,random_state = 55))\n",
    "print(df['toxic'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df = train_test_split(df, test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_df[\"toxic\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_df[\"toxic\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загрузили данные, просмотрели случайные строки из них, разделили датасет на тренировочную и тестовую"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обучение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "snowball = SnowballStemmer(language=\"english\")\n",
    "stop_words = stopwords.words(\"english\")\n",
    "\n",
    "def tokenize_sentence(sentence: str, remove_stop_words: bool = True):\n",
    "    tokens = word_tokenize(sentence, language=\"russian\")\n",
    "    tokens = [i for i in tokens if i not in string.punctuation]\n",
    "    if remove_stop_words:\n",
    "        tokens = [i for i in tokens if i not in stop_words]\n",
    "    tokens = [snowball.stem(i) for i in tokens]\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(tokenizer=lambda x: tokenize_sentence(x, remove_stop_words=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = vectorizer.fit_transform(train_df[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6.88 s, sys: 4.04 s, total: 10.9 s\n",
      "Wall time: 10.9 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=0, solver='warn', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model = LogisticRegression(random_state=0)\n",
    "model.fit(features, train_df[\"toxic\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 153 µs, sys: 4 µs, total: 157 µs\n",
      "Wall time: 162 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model_pipeline = Pipeline([\n",
    "    (\"vectorizer\", TfidfVectorizer(tokenizer=lambda x: tokenize_sentence(x, remove_stop_words=True))),\n",
    "    (\"model\", LogisticRegression(random_state=0))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3min 47s, sys: 4.18 s, total: 3min 51s\n",
      "Wall time: 3min 52s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('vectorizer',\n",
       "                 TfidfVectorizer(analyzer='word', binary=False,\n",
       "                                 decode_error='strict',\n",
       "                                 dtype=<class 'numpy.float64'>,\n",
       "                                 encoding='utf-8', input='content',\n",
       "                                 lowercase=True, max_df=1.0, max_features=None,\n",
       "                                 min_df=1, ngram_range=(1, 1), norm='l2',\n",
       "                                 preprocessor=None, smooth_idf=True,\n",
       "                                 stop_words=None, strip_accents=None,\n",
       "                                 sublinear_tf=False,\n",
       "                                 token_patt...u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                                 tokenizer=<function <lambda> at 0x7efd7dcd3dd0>,\n",
       "                                 use_idf=True, vocabulary=None)),\n",
       "                ('model',\n",
       "                 LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
       "                                    fit_intercept=True, intercept_scaling=1,\n",
       "                                    l1_ratio=None, max_iter=100,\n",
       "                                    multi_class='warn', n_jobs=None,\n",
       "                                    penalty='l2', random_state=0, solver='warn',\n",
       "                                    tol=0.0001, verbose=0, warm_start=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model_pipeline.fit(train_df[\"text\"], train_df[\"toxic\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "F1: 0.7315267288612468\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nF1:\", f1_score(test_df['toxic'], model_pipeline.predict(test_df[\"text\"])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "значение F1 меры меньше требуемого, попробуем его поднять, за счёт подбора гиперпараметров"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prec, rec, thresholds = precision_recall_curve(y_true=test_df[\"toxic\"], probas_pred=model_pipeline.predict_proba(test_df[\"text\"])[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 212 µs, sys: 4 µs, total: 216 µs\n",
      "Wall time: 223 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "grid_pipeline = Pipeline([\n",
    "    (\"vectorizer\", TfidfVectorizer(tokenizer=lambda x: tokenize_sentence(x, remove_stop_words=True))),\n",
    "    (\"model\", \n",
    "     GridSearchCV(\n",
    "        LogisticRegression(random_state=0),\n",
    "        param_grid={'C': [0.1, 1, 10.]},\n",
    "        cv=3,\n",
    "         verbose=4\n",
    "        )\n",
    "    )\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 3 candidates, totalling 9 fits\n",
      "[CV] C=0.1 ...........................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ............................... C=0.1, score=0.928, total=   5.9s\n",
      "[CV] C=0.1 ...........................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    5.9s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ............................... C=0.1, score=0.928, total=   6.0s\n",
      "[CV] C=0.1 ...........................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:   11.9s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ............................... C=0.1, score=0.928, total=   5.9s\n",
      "[CV] C=1 .............................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:   17.8s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................................. C=1, score=0.952, total=   8.6s\n",
      "[CV] C=1 .............................................................\n",
      "[CV] ................................. C=1, score=0.952, total=  10.5s\n",
      "[CV] C=1 .............................................................\n",
      "[CV] ................................. C=1, score=0.953, total=  10.3s\n",
      "[CV] C=10.0 ..........................................................\n",
      "[CV] .............................. C=10.0, score=0.958, total=  16.0s\n",
      "[CV] C=10.0 ..........................................................\n",
      "[CV] .............................. C=10.0, score=0.958, total=  16.1s\n",
      "[CV] C=10.0 ..........................................................\n",
      "[CV] .............................. C=10.0, score=0.959, total=  15.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:  1.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4min 45s, sys: 48.1 s, total: 5min 34s\n",
      "Wall time: 5min 36s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('vectorizer',\n",
       "                 TfidfVectorizer(analyzer='word', binary=False,\n",
       "                                 decode_error='strict',\n",
       "                                 dtype=<class 'numpy.float64'>,\n",
       "                                 encoding='utf-8', input='content',\n",
       "                                 lowercase=True, max_df=1.0, max_features=None,\n",
       "                                 min_df=1, ngram_range=(1, 1), norm='l2',\n",
       "                                 preprocessor=None, smooth_idf=True,\n",
       "                                 stop_words=None, strip_accents=None,\n",
       "                                 sublinear_tf=False,\n",
       "                                 token_patt...\n",
       "                                                           class_weight=None,\n",
       "                                                           dual=False,\n",
       "                                                           fit_intercept=True,\n",
       "                                                           intercept_scaling=1,\n",
       "                                                           l1_ratio=None,\n",
       "                                                           max_iter=100,\n",
       "                                                           multi_class='warn',\n",
       "                                                           n_jobs=None,\n",
       "                                                           penalty='l2',\n",
       "                                                           random_state=0,\n",
       "                                                           solver='warn',\n",
       "                                                           tol=0.0001,\n",
       "                                                           verbose=0,\n",
       "                                                           warm_start=False),\n",
       "                              iid='warn', n_jobs=None,\n",
       "                              param_grid={'C': [0.1, 1, 10.0]},\n",
       "                              pre_dispatch='2*n_jobs', refit=True,\n",
       "                              return_train_score=False, scoring=None,\n",
       "                              verbose=4))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "grid_pipeline.fit(train_df[\"text\"], train_df[\"toxic\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Лучший результат показли при C = 10. Используем его в дальнейшем"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 161 µs, sys: 12 µs, total: 173 µs\n",
      "Wall time: 179 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model_pipeline_c_10 = Pipeline([\n",
    "    (\"vectorizer\", TfidfVectorizer(tokenizer=lambda x: tokenize_sentence(x, remove_stop_words=True))),\n",
    "    (\"model\", LogisticRegression(random_state=0, C=10.))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3min 52s, sys: 7.12 s, total: 3min 59s\n",
      "Wall time: 4min 3s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('vectorizer',\n",
       "                 TfidfVectorizer(analyzer='word', binary=False,\n",
       "                                 decode_error='strict',\n",
       "                                 dtype=<class 'numpy.float64'>,\n",
       "                                 encoding='utf-8', input='content',\n",
       "                                 lowercase=True, max_df=1.0, max_features=None,\n",
       "                                 min_df=1, ngram_range=(1, 1), norm='l2',\n",
       "                                 preprocessor=None, smooth_idf=True,\n",
       "                                 stop_words=None, strip_accents=None,\n",
       "                                 sublinear_tf=False,\n",
       "                                 token_patt...)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                                 tokenizer=<function <lambda> at 0x7efd780004d0>,\n",
       "                                 use_idf=True, vocabulary=None)),\n",
       "                ('model',\n",
       "                 LogisticRegression(C=10.0, class_weight=None, dual=False,\n",
       "                                    fit_intercept=True, intercept_scaling=1,\n",
       "                                    l1_ratio=None, max_iter=100,\n",
       "                                    multi_class='warn', n_jobs=None,\n",
       "                                    penalty='l2', random_state=0, solver='warn',\n",
       "                                    tol=0.0001, verbose=0, warm_start=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model_pipeline_c_10.fit(train_df[\"text\"], train_df[\"toxic\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "F1: 0.773162066138289\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nF1:\", f1_score(test_df['toxic'], model_pipeline_c_10.predict(test_df[\"text\"])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Выводы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучили модель логистической регрессии, которая может определять токсичные комментарии. Для этого разбили исходные комментарии на токены, затем использовали pipeline, чтобы модели могла принимать на вход целые предложения. Повысили точность f1 меры с помощью подбора гиперпаметра."
   ]
  }
 ],
 "metadata": {
  "ExecuteTimeLog": [
   {
    "duration": 285,
    "start_time": "2021-07-27T12:52:28.846Z"
   },
   {
    "duration": 529,
    "start_time": "2021-07-27T12:52:33.533Z"
   },
   {
    "duration": 631,
    "start_time": "2021-07-27T12:52:34.064Z"
   },
   {
    "duration": 433,
    "start_time": "2021-07-27T12:54:02.153Z"
   },
   {
    "duration": 151,
    "start_time": "2021-07-27T12:58:42.382Z"
   },
   {
    "duration": 578,
    "start_time": "2021-07-27T13:02:26.178Z"
   },
   {
    "duration": 1265,
    "start_time": "2021-07-27T13:02:58.946Z"
   },
   {
    "duration": 5,
    "start_time": "2021-07-27T13:04:12.302Z"
   },
   {
    "duration": 605,
    "start_time": "2021-07-27T13:04:16.203Z"
   },
   {
    "duration": 621,
    "start_time": "2021-07-27T13:06:52.588Z"
   },
   {
    "duration": 641,
    "start_time": "2021-07-27T13:07:23.978Z"
   },
   {
    "duration": 611,
    "start_time": "2021-07-27T13:07:40.406Z"
   },
   {
    "duration": 610,
    "start_time": "2021-07-27T13:08:22.880Z"
   },
   {
    "duration": 584,
    "start_time": "2021-07-27T13:19:39.531Z"
   },
   {
    "duration": 593,
    "start_time": "2021-07-27T13:20:04.413Z"
   },
   {
    "duration": 924,
    "start_time": "2021-07-27T13:20:24.327Z"
   },
   {
    "duration": 767,
    "start_time": "2021-07-27T13:20:55.683Z"
   },
   {
    "duration": 607,
    "start_time": "2021-07-27T13:21:27.556Z"
   },
   {
    "duration": 23,
    "start_time": "2021-07-27T13:33:00.643Z"
   },
   {
    "duration": 34,
    "start_time": "2021-07-27T13:33:28.784Z"
   },
   {
    "duration": 32,
    "start_time": "2021-07-27T13:33:44.289Z"
   },
   {
    "duration": 7,
    "start_time": "2021-07-27T13:33:48.719Z"
   },
   {
    "duration": 6,
    "start_time": "2021-07-27T13:36:08.484Z"
   },
   {
    "duration": 4,
    "start_time": "2021-07-27T13:40:23.686Z"
   },
   {
    "duration": 395,
    "start_time": "2021-07-27T13:41:04.934Z"
   },
   {
    "duration": 1932,
    "start_time": "2021-07-27T18:08:55.635Z"
   },
   {
    "duration": 654,
    "start_time": "2021-07-27T18:08:59.309Z"
   },
   {
    "duration": 1159,
    "start_time": "2021-07-27T18:10:22.234Z"
   },
   {
    "duration": 24,
    "start_time": "2021-07-27T18:13:00.642Z"
   },
   {
    "duration": 3,
    "start_time": "2021-07-27T18:13:00.975Z"
   },
   {
    "duration": 3,
    "start_time": "2021-07-27T18:13:01.738Z"
   },
   {
    "duration": 512343,
    "start_time": "2021-07-27T18:13:02.422Z"
   },
   {
    "duration": 5,
    "start_time": "2021-07-27T18:22:05.113Z"
   },
   {
    "duration": 595,
    "start_time": "2021-07-27T18:22:05.829Z"
   },
   {
    "duration": 29,
    "start_time": "2021-07-27T18:22:06.707Z"
   },
   {
    "duration": 6466,
    "start_time": "2021-07-27T18:22:08.440Z"
   },
   {
    "duration": 4,
    "start_time": "2021-07-27T18:24:08.312Z"
   },
   {
    "duration": 5,
    "start_time": "2021-07-27T18:24:15.999Z"
   },
   {
    "duration": 5,
    "start_time": "2021-07-27T18:24:20.888Z"
   },
   {
    "duration": 4,
    "start_time": "2021-07-27T18:24:25.451Z"
   },
   {
    "duration": 4,
    "start_time": "2021-07-27T18:24:28.957Z"
   },
   {
    "duration": 7,
    "start_time": "2021-07-27T18:24:46.328Z"
   },
   {
    "duration": 580,
    "start_time": "2021-07-27T18:25:07.053Z"
   },
   {
    "duration": 610,
    "start_time": "2021-07-27T18:25:11.563Z"
   },
   {
    "duration": 775,
    "start_time": "2021-07-27T18:25:15.523Z"
   },
   {
    "duration": 615,
    "start_time": "2021-07-27T18:25:22.584Z"
   },
   {
    "duration": 4,
    "start_time": "2021-07-27T18:25:38.895Z"
   },
   {
    "duration": 709,
    "start_time": "2021-07-27T18:26:05.022Z"
   },
   {
    "duration": 648,
    "start_time": "2021-07-27T18:26:19.512Z"
   },
   {
    "duration": 604,
    "start_time": "2021-07-27T18:26:27.026Z"
   },
   {
    "duration": 897,
    "start_time": "2021-07-27T18:26:39.295Z"
   },
   {
    "duration": 672,
    "start_time": "2021-07-27T18:27:08.842Z"
   },
   {
    "duration": 4,
    "start_time": "2021-07-27T18:29:25.901Z"
   },
   {
    "duration": 923,
    "start_time": "2021-07-27T18:29:27.045Z"
   },
   {
    "duration": 3,
    "start_time": "2021-07-27T18:30:04.148Z"
   },
   {
    "duration": 675,
    "start_time": "2021-07-27T18:30:04.610Z"
   },
   {
    "duration": 1407,
    "start_time": "2021-07-27T19:09:05.202Z"
   },
   {
    "duration": 604,
    "start_time": "2021-07-27T19:09:08.625Z"
   },
   {
    "duration": 26,
    "start_time": "2021-07-27T19:09:09.804Z"
   },
   {
    "duration": 4,
    "start_time": "2021-07-27T19:09:10.445Z"
   },
   {
    "duration": 3,
    "start_time": "2021-07-27T19:09:11.045Z"
   },
   {
    "duration": 348,
    "start_time": "2021-07-27T19:09:15.081Z"
   },
   {
    "duration": 652,
    "start_time": "2021-07-27T19:09:38.968Z"
   },
   {
    "duration": 164,
    "start_time": "2021-07-27T19:09:42.221Z"
   },
   {
    "duration": 1549,
    "start_time": "2021-07-27T19:21:15.680Z"
   },
   {
    "duration": 626,
    "start_time": "2021-07-27T19:21:20.108Z"
   },
   {
    "duration": 25,
    "start_time": "2021-07-27T19:21:21.493Z"
   },
   {
    "duration": 4,
    "start_time": "2021-07-27T19:21:22.107Z"
   },
   {
    "duration": 384,
    "start_time": "2021-07-27T19:21:23.116Z"
   },
   {
    "duration": 3,
    "start_time": "2021-07-27T19:21:33.098Z"
   },
   {
    "duration": 210692,
    "start_time": "2021-07-27T19:21:39.631Z"
   },
   {
    "duration": 5,
    "start_time": "2021-07-27T19:33:19.592Z"
   },
   {
    "duration": 9,
    "start_time": "2021-07-27T19:33:29.470Z"
   },
   {
    "duration": 109,
    "start_time": "2021-07-27T19:34:07.441Z"
   },
   {
    "duration": 3,
    "start_time": "2021-07-27T19:34:10.733Z"
   },
   {
    "duration": 3,
    "start_time": "2021-07-27T19:34:43.515Z"
   },
   {
    "duration": 3,
    "start_time": "2021-07-27T19:40:51.596Z"
   },
   {
    "duration": 632,
    "start_time": "2021-07-27T19:40:52.508Z"
   },
   {
    "duration": 2027,
    "start_time": "2021-07-28T06:40:13.840Z"
   },
   {
    "duration": 791,
    "start_time": "2021-07-28T06:40:17.256Z"
   },
   {
    "duration": 39,
    "start_time": "2021-07-28T06:40:18.050Z"
   },
   {
    "duration": 6,
    "start_time": "2021-07-28T06:40:18.941Z"
   },
   {
    "duration": 5,
    "start_time": "2021-07-28T06:40:24.999Z"
   },
   {
    "duration": 974,
    "start_time": "2021-07-28T06:40:25.405Z"
   },
   {
    "duration": 651,
    "start_time": "2021-07-28T06:40:55.151Z"
   },
   {
    "duration": 6,
    "start_time": "2021-07-28T06:40:58.549Z"
   },
   {
    "duration": 1256,
    "start_time": "2021-07-28T06:40:58.924Z"
   },
   {
    "duration": 9,
    "start_time": "2021-07-28T06:41:26.984Z"
   },
   {
    "duration": 5,
    "start_time": "2021-07-28T06:41:27.567Z"
   },
   {
    "duration": 5,
    "start_time": "2021-07-28T06:43:43.951Z"
   },
   {
    "duration": 155294,
    "start_time": "2021-07-28T06:43:47.805Z"
   },
   {
    "duration": 4,
    "start_time": "2021-07-28T06:49:18.026Z"
   },
   {
    "duration": 384,
    "start_time": "2021-07-28T06:49:18.571Z"
   },
   {
    "duration": 12531,
    "start_time": "2021-07-28T06:49:28.520Z"
   },
   {
    "duration": 7,
    "start_time": "2021-07-28T06:50:38.779Z"
   },
   {
    "duration": 43,
    "start_time": "2021-07-28T06:50:50.500Z"
   },
   {
    "duration": 9,
    "start_time": "2021-07-28T06:50:51.720Z"
   },
   {
    "duration": 4,
    "start_time": "2021-07-28T07:00:01.564Z"
   },
   {
    "duration": 407,
    "start_time": "2021-07-28T07:00:02.190Z"
   },
   {
    "duration": 130,
    "start_time": "2021-07-28T07:00:11.168Z"
   },
   {
    "duration": 9463,
    "start_time": "2021-07-28T07:00:19.919Z"
   },
   {
    "duration": 167511,
    "start_time": "2021-07-28T07:00:35.141Z"
   },
   {
    "duration": 52284,
    "start_time": "2021-07-28T07:03:35.980Z"
   },
   {
    "duration": 155643,
    "start_time": "2021-07-28T07:06:47.044Z"
   },
   {
    "duration": 413,
    "start_time": "2021-07-28T07:24:00.349Z"
   },
   {
    "duration": 8,
    "start_time": "2021-07-28T07:24:13.065Z"
   },
   {
    "duration": 430,
    "start_time": "2021-07-28T07:24:17.116Z"
   },
   {
    "duration": 143,
    "start_time": "2021-07-28T07:25:08.077Z"
   },
   {
    "duration": 61,
    "start_time": "2021-07-28T07:25:22.622Z"
   },
   {
    "duration": 305,
    "start_time": "2021-07-28T07:25:34.745Z"
   },
   {
    "duration": 426902,
    "start_time": "2021-07-28T07:25:45.630Z"
   },
   {
    "duration": 530,
    "start_time": "2021-07-28T07:33:31.440Z"
   },
   {
    "duration": 427,
    "start_time": "2021-07-28T07:34:12.339Z"
   },
   {
    "duration": 31,
    "start_time": "2021-07-28T07:34:16.439Z"
   },
   {
    "duration": 396,
    "start_time": "2021-07-28T07:34:17.141Z"
   },
   {
    "duration": 5284,
    "start_time": "2021-07-28T07:35:17.197Z"
   },
   {
    "duration": 6,
    "start_time": "2021-07-28T07:37:39.231Z"
   },
   {
    "duration": 6,
    "start_time": "2021-07-28T07:37:46.921Z"
   },
   {
    "duration": 380,
    "start_time": "2021-07-28T07:38:57.318Z"
   },
   {
    "duration": 5,
    "start_time": "2021-07-28T07:39:18.701Z"
   },
   {
    "duration": 58088,
    "start_time": "2021-07-28T07:40:34.955Z"
   },
   {
    "duration": 6,
    "start_time": "2021-07-28T07:42:11.300Z"
   },
   {
    "duration": 5,
    "start_time": "2021-07-28T07:42:21.399Z"
   },
   {
    "duration": 6,
    "start_time": "2021-07-28T07:42:29.226Z"
   },
   {
    "duration": 33104,
    "start_time": "2021-07-28T07:42:55.755Z"
   },
   {
    "duration": 138,
    "start_time": "2021-07-28T07:44:31.007Z"
   },
   {
    "duration": 4,
    "start_time": "2021-07-28T07:44:37.792Z"
   },
   {
    "duration": 375,
    "start_time": "2021-07-28T07:44:55.418Z"
   },
   {
    "duration": 80,
    "start_time": "2021-07-28T07:44:59.256Z"
   },
   {
    "duration": 251,
    "start_time": "2021-07-28T07:46:02.514Z"
   },
   {
    "duration": 759,
    "start_time": "2021-07-28T07:46:03.176Z"
   },
   {
    "duration": 418060,
    "start_time": "2021-07-28T07:46:12.477Z"
   },
   {
    "duration": 55,
    "start_time": "2021-07-28T07:53:15.620Z"
   },
   {
    "duration": 32665,
    "start_time": "2021-07-28T07:53:21.419Z"
   },
   {
    "duration": 1092335,
    "start_time": "2021-07-28T07:54:52.322Z"
   },
   {
    "duration": 300,
    "start_time": "2021-07-28T08:15:20.507Z"
   },
   {
    "duration": 35821,
    "start_time": "2021-07-28T08:16:11.333Z"
   },
   {
    "duration": 15964,
    "start_time": "2021-07-28T08:16:47.156Z"
   },
   {
    "duration": 1450,
    "start_time": "2021-07-28T08:19:28.113Z"
   },
   {
    "duration": 8,
    "start_time": "2021-07-28T08:19:56.239Z"
   },
   {
    "duration": 4,
    "start_time": "2021-07-28T08:20:02.031Z"
   },
   {
    "duration": 28664,
    "start_time": "2021-07-28T08:20:17.665Z"
   },
   {
    "duration": 122063,
    "start_time": "2021-07-28T08:20:46.331Z"
   },
   {
    "duration": 30692,
    "start_time": "2021-07-28T08:22:48.397Z"
   },
   {
    "duration": 10947,
    "start_time": "2021-07-28T08:23:19.092Z"
   },
   {
    "duration": 2038,
    "start_time": "2021-07-28T08:25:49.331Z"
   },
   {
    "duration": 813,
    "start_time": "2021-07-28T08:25:51.372Z"
   },
   {
    "duration": 420963,
    "start_time": "2021-07-28T08:25:52.187Z"
   },
   {
    "duration": 44,
    "start_time": "2021-07-28T08:32:53.153Z"
   },
   {
    "duration": 4,
    "start_time": "2021-07-28T08:32:53.200Z"
   },
   {
    "duration": 18,
    "start_time": "2021-07-28T08:32:53.207Z"
   },
   {
    "duration": 28641,
    "start_time": "2021-07-28T08:32:53.227Z"
   },
   {
    "duration": 165098,
    "start_time": "2021-07-28T08:33:21.871Z"
   },
   {
    "duration": 30364,
    "start_time": "2021-07-28T08:36:06.971Z"
   },
   {
    "duration": 11680,
    "start_time": "2021-07-28T08:36:37.338Z"
   },
   {
    "duration": 10477,
    "start_time": "2021-07-28T08:38:12.574Z"
   },
   {
    "duration": 338842,
    "start_time": "2021-07-28T08:38:23.054Z"
   },
   {
    "duration": 7,
    "start_time": "2021-07-28T09:11:22.842Z"
   },
   {
    "duration": 739,
    "start_time": "2021-07-28T09:11:23.564Z"
   },
   {
    "duration": 42,
    "start_time": "2021-07-28T09:11:25.077Z"
   },
   {
    "duration": 8,
    "start_time": "2021-07-28T09:11:40.430Z"
   },
   {
    "duration": 9,
    "start_time": "2021-07-28T09:11:41.468Z"
   },
   {
    "duration": 603,
    "start_time": "2021-07-28T09:12:12.837Z"
   },
   {
    "duration": 1979,
    "start_time": "2021-07-28T09:12:55.081Z"
   },
   {
    "duration": 826,
    "start_time": "2021-07-28T09:13:14.695Z"
   },
   {
    "duration": 30,
    "start_time": "2021-07-28T09:13:15.523Z"
   },
   {
    "duration": 8,
    "start_time": "2021-07-28T09:13:16.001Z"
   },
   {
    "duration": 10,
    "start_time": "2021-07-28T09:13:16.624Z"
   },
   {
    "duration": 536,
    "start_time": "2021-07-28T09:13:18.149Z"
   },
   {
    "duration": 7,
    "start_time": "2021-07-28T09:13:41.040Z"
   },
   {
    "duration": 9,
    "start_time": "2021-07-28T09:13:43.165Z"
   },
   {
    "duration": 4,
    "start_time": "2021-07-28T09:13:54.089Z"
   },
   {
    "duration": 154660,
    "start_time": "2021-07-28T09:14:03.247Z"
   },
   {
    "duration": 7,
    "start_time": "2021-07-28T09:18:32.979Z"
   },
   {
    "duration": 38,
    "start_time": "2021-07-28T09:18:34.098Z"
   },
   {
    "duration": 146279,
    "start_time": "2021-07-28T09:18:44.710Z"
   },
   {
    "duration": 263,
    "start_time": "2021-07-28T09:22:53.965Z"
   },
   {
    "duration": 4,
    "start_time": "2021-07-28T09:23:17.850Z"
   },
   {
    "duration": 10074,
    "start_time": "2021-07-28T09:23:18.681Z"
   },
   {
    "duration": 156931,
    "start_time": "2021-07-28T09:23:42.798Z"
   },
   {
    "duration": 596,
    "start_time": "2021-07-28T09:26:19.732Z"
   },
   {
    "duration": 50557,
    "start_time": "2021-07-28T09:27:15.965Z"
   },
   {
    "duration": 8,
    "start_time": "2021-07-28T09:37:58.676Z"
   },
   {
    "duration": 13138,
    "start_time": "2021-07-28T09:38:02.524Z"
   },
   {
    "duration": 47653,
    "start_time": "2021-07-28T09:38:38.123Z"
   },
   {
    "duration": 5,
    "start_time": "2021-07-28T09:39:33.724Z"
   },
   {
    "duration": 376,
    "start_time": "2021-07-28T09:43:02.601Z"
   },
   {
    "duration": 436,
    "start_time": "2021-07-28T09:43:26.365Z"
   },
   {
    "duration": 1150,
    "start_time": "2021-07-28T09:43:57.011Z"
   },
   {
    "duration": 509,
    "start_time": "2021-07-28T09:44:07.441Z"
   },
   {
    "duration": 521,
    "start_time": "2021-07-28T09:44:31.011Z"
   },
   {
    "duration": 8,
    "start_time": "2021-07-28T09:45:30.149Z"
   },
   {
    "duration": 421,
    "start_time": "2021-07-28T09:45:41.164Z"
   },
   {
    "duration": 432,
    "start_time": "2021-07-28T09:46:21.322Z"
   },
   {
    "duration": 8,
    "start_time": "2021-07-28T09:46:59.235Z"
   },
   {
    "duration": 429,
    "start_time": "2021-07-28T09:47:15.135Z"
   },
   {
    "duration": 405,
    "start_time": "2021-07-28T09:53:57.868Z"
   },
   {
    "duration": 228,
    "start_time": "2021-07-28T09:54:26.017Z"
   },
   {
    "duration": 429,
    "start_time": "2021-07-28T09:55:15.147Z"
   },
   {
    "duration": 7,
    "start_time": "2021-07-28T09:55:35.622Z"
   },
   {
    "duration": 10341,
    "start_time": "2021-07-28T10:04:57.318Z"
   },
   {
    "duration": 140,
    "start_time": "2021-07-28T10:05:54.276Z"
   },
   {
    "duration": 152,
    "start_time": "2021-07-28T10:06:37.609Z"
   },
   {
    "duration": 49248,
    "start_time": "2021-07-28T10:08:13.250Z"
   },
   {
    "duration": 66561,
    "start_time": "2021-07-28T10:10:44.516Z"
   },
   {
    "duration": 10324,
    "start_time": "2021-07-28T10:12:16.183Z"
   },
   {
    "duration": 48363,
    "start_time": "2021-07-28T10:12:30.547Z"
   },
   {
    "duration": 48007,
    "start_time": "2021-07-28T10:13:30.508Z"
   },
   {
    "duration": 5,
    "start_time": "2021-07-28T10:16:27.801Z"
   },
   {
    "duration": 259623,
    "start_time": "2021-07-28T10:16:35.004Z"
   },
   {
    "duration": 150,
    "start_time": "2021-07-28T10:20:54.632Z"
   },
   {
    "duration": 245,
    "start_time": "2021-07-28T10:20:54.539Z"
   },
   {
    "duration": 237,
    "start_time": "2021-07-28T10:20:54.548Z"
   },
   {
    "duration": 5,
    "start_time": "2021-07-28T10:21:59.328Z"
   },
   {
    "duration": 11397,
    "start_time": "2021-07-28T10:22:05.507Z"
   },
   {
    "duration": 171589,
    "start_time": "2021-07-28T10:22:51.034Z"
   },
   {
    "duration": 49155,
    "start_time": "2021-07-28T10:25:53.600Z"
   },
   {
    "duration": 275,
    "start_time": "2021-07-28T11:37:31.219Z"
   },
   {
    "duration": 7,
    "start_time": "2021-07-28T11:38:03.191Z"
   },
   {
    "duration": 1819,
    "start_time": "2021-07-28T11:43:17.025Z"
   },
   {
    "duration": 938,
    "start_time": "2021-07-28T11:43:18.852Z"
   },
   {
    "duration": 34,
    "start_time": "2021-07-28T11:43:19.793Z"
   },
   {
    "duration": 8,
    "start_time": "2021-07-28T11:43:19.829Z"
   },
   {
    "duration": 9,
    "start_time": "2021-07-28T11:43:19.868Z"
   },
   {
    "duration": 10,
    "start_time": "2021-07-28T11:43:19.879Z"
   },
   {
    "duration": 5,
    "start_time": "2021-07-28T11:43:19.892Z"
   },
   {
    "duration": 443,
    "start_time": "2021-07-28T11:43:19.902Z"
   },
   {
    "duration": 5,
    "start_time": "2021-07-28T11:43:20.348Z"
   },
   {
    "duration": 161486,
    "start_time": "2021-07-28T11:43:20.355Z"
   },
   {
    "duration": 48926,
    "start_time": "2021-07-28T11:46:01.844Z"
   },
   {
    "duration": 4,
    "start_time": "2021-07-28T11:46:50.773Z"
   },
   {
    "duration": 14,
    "start_time": "2021-07-28T11:46:50.780Z"
   },
   {
    "duration": 260539,
    "start_time": "2021-07-28T11:46:50.797Z"
   },
   {
    "duration": 6,
    "start_time": "2021-07-28T11:51:11.338Z"
   },
   {
    "duration": 171587,
    "start_time": "2021-07-28T11:51:11.347Z"
   },
   {
    "duration": 49364,
    "start_time": "2021-07-28T11:54:02.937Z"
   },
   {
    "duration": 130,
    "start_time": "2021-07-28T11:55:29.501Z"
   },
   {
    "duration": 51654,
    "start_time": "2021-07-28T11:55:35.187Z"
   },
   {
    "duration": 147517,
    "start_time": "2021-07-28T11:58:24.985Z"
   },
   {
    "duration": 10813,
    "start_time": "2021-07-28T12:01:27.012Z"
   },
   {
    "duration": 6,
    "start_time": "2021-07-28T12:01:49.362Z"
   },
   {
    "duration": 162061,
    "start_time": "2021-07-28T12:01:49.774Z"
   },
   {
    "duration": 49045,
    "start_time": "2021-07-28T12:04:31.839Z"
   },
   {
    "duration": 6,
    "start_time": "2021-07-28T12:06:06.467Z"
   },
   {
    "duration": 50,
    "start_time": "2021-07-28T12:06:07.138Z"
   },
   {
    "duration": 2108,
    "start_time": "2021-07-28T12:06:21.543Z"
   },
   {
    "duration": 815,
    "start_time": "2021-07-28T12:06:23.654Z"
   },
   {
    "duration": 31,
    "start_time": "2021-07-28T12:06:24.472Z"
   },
   {
    "duration": 3,
    "start_time": "2021-07-28T12:06:24.506Z"
   },
   {
    "duration": 9,
    "start_time": "2021-07-28T12:06:24.511Z"
   },
   {
    "duration": 8,
    "start_time": "2021-07-28T12:06:24.523Z"
   },
   {
    "duration": 36,
    "start_time": "2021-07-28T12:06:24.534Z"
   },
   {
    "duration": 232732,
    "start_time": "2021-07-28T12:06:24.572Z"
   },
   {
    "duration": 10818,
    "start_time": "2021-07-28T12:10:17.308Z"
   },
   {
    "duration": 5,
    "start_time": "2021-07-28T12:10:28.129Z"
   },
   {
    "duration": 232697,
    "start_time": "2021-07-28T12:10:28.136Z"
   },
   {
    "duration": 76199,
    "start_time": "2021-07-28T12:14:20.835Z"
   },
   {
    "duration": 3,
    "start_time": "2021-07-28T12:15:37.036Z"
   },
   {
    "duration": 13,
    "start_time": "2021-07-28T12:15:37.041Z"
   },
   {
    "duration": 336864,
    "start_time": "2021-07-28T12:15:37.068Z"
   },
   {
    "duration": 5,
    "start_time": "2021-07-28T12:21:13.935Z"
   },
   {
    "duration": 243888,
    "start_time": "2021-07-28T12:21:13.942Z"
   },
   {
    "duration": 78993,
    "start_time": "2021-07-28T12:25:17.833Z"
   },
   {
    "duration": 2247,
    "start_time": "2021-07-29T09:52:01.904Z"
   },
   {
    "duration": 765,
    "start_time": "2021-07-29T09:52:04.153Z"
   },
   {
    "duration": 28,
    "start_time": "2021-07-29T09:52:07.498Z"
   },
   {
    "duration": 3,
    "start_time": "2021-07-29T09:52:07.914Z"
   },
   {
    "duration": 3,
    "start_time": "2021-07-29T09:52:08.427Z"
   },
   {
    "duration": 7,
    "start_time": "2021-07-29T09:52:10.111Z"
   },
   {
    "duration": 4,
    "start_time": "2021-07-29T09:52:12.804Z"
   },
   {
    "duration": 215695,
    "start_time": "2021-07-29T09:52:13.210Z"
   },
   {
    "duration": 37,
    "start_time": "2021-07-29T09:56:45.255Z"
   },
   {
    "duration": 10925,
    "start_time": "2021-07-29T09:56:53.924Z"
   },
   {
    "duration": 6,
    "start_time": "2021-07-29T09:58:10.463Z"
   },
   {
    "duration": 428,
    "start_time": "2021-07-29T09:58:16.353Z"
   }
  ],
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Содержание",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "302.391px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
